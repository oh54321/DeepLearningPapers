{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This is an implementation of GANs, which are used to generate images\n",
        "# The idea here is that we train two neural networks. One distinguished between real and fake images, and the other tries to generate fake images that fool the discriminator\n",
        "# As long as one network doesn't get too good at beating the other, over time these two networks get better at playing this game with each other\n",
        "# So the generator eventually gets great at generating realistic images"
      ],
      "metadata": {
        "id": "2khiNM4Kukxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOWSU4xg4u6z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "! pip install torch-lr-finder\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastai.tabular.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYVPVHah8aSP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from fastbook import *\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6t3yQsICdeb"
      },
      "outputs": [],
      "source": [
        "DISC_STEPS = 40 # Number of batches we train the discriminator on before training the generator\n",
        "BATCH_SIZE = 64 # batch size\n",
        "NUM_ITERATIONS = 1000 # number of iterations we train for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md9onaog82Xn"
      },
      "outputs": [],
      "source": [
        "# Image discriminator network - discriminates between whether an image is real or fake\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size = 3, stride = 1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size = 4,  stride = 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size = 4,  stride = 2),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        return self.model(batch)\n",
        "\n",
        "# Image generation network - generates an image that is as likely as possible for the discriminator to believe is real\n",
        "\n",
        "class generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 224, 4, 1, 0),\n",
        "            nn.BatchNorm2d(224),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(224, 112, 4, 2, 1),\n",
        "            nn.BatchNorm2d(112),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(112, 56, 4, 2, 1),\n",
        "            nn.BatchNorm2d(56),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(56, 28, 4, 2, 1),\n",
        "            nn.BatchNorm2d(28),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d( 28, 1, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self):\n",
        "        return self.main(torch.randn(1, 100, 1, 1)) # Our input is a ''noise'' vector, used to create some randomness in our generated image\n",
        "\n",
        "# Tries loading previously trained models\n",
        "disc_net = discriminator()\n",
        "gen_net = generator()\n",
        "\n",
        "try:\n",
        "  disc_net.load_state_dict(torch.load(\"gdrive/MyDrive/disc_net\"))\n",
        "  gen_net.load_state_dict(torch.load(\"gdrive/MyDrive/gen_net\"))\n",
        "except:\n",
        "  print(\"Previous models not found\")\n",
        "\n",
        "disc_optimizer = torch.optim.Adam(params = \n",
        "            disc_net.parameters(), lr=0.001)\n",
        "gen_optimizer = torch.optim.Adam(params = \n",
        "            gen_net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNsqnd_sWQzQ"
      },
      "outputs": [],
      "source": [
        "# Converts array to a tensor of floats\n",
        "def toTensor(arr, dtype=torch.float32):\n",
        "  return torch.tensor(arr, dtype = dtype)\n",
        "\n",
        "# Turns stack of tensors into a batched dataset\n",
        "def batchData(data, bs = 64):\n",
        "  data_size = len(data)\n",
        "  return [toTensor(data[i:min(i + bs, data_size)]) for i in range(0, data_size, bs)]\n",
        "\n",
        "# Loads MNIST Data, data of images of numbers\n",
        "image_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    download=True,\n",
        "    transform=transforms.Compose([transforms.ToTensor(), transforms.Resize((64, 64))]))\n",
        "\n",
        "# Throws out labels of numbers, batches this data\n",
        "image_batches = batchData(torch.stack([img for img, label in image_data]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g_qI-KdLNMxh"
      },
      "outputs": [],
      "source": [
        "# Used to deal with rounding errors where the probability of something is views as 0, which is impossible to take the log of in loss functions\n",
        "def smooth(tens):\n",
        "  if float(tens) > 10**-10:\n",
        "    return tens\n",
        "  return tens+10**-10\n",
        "\n",
        "# Loss function for discriminator network\n",
        "def disc_loss(real_preds, fake_preds):\n",
        "  return -1*torch.mean(torch.stack([torch.log(smooth(real_preds[i]))+torch.log(smooth(1-fake_preds[i])) for i in range(len(real_preds))]))\n",
        "\n",
        "# Loss function for generator network\n",
        "def gen_loss(fake_preds):\n",
        "  return torch.mean(torch.stack([torch.log(smooth(1-fake_preds[i])) for i in range(len(fake_preds))]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc_losses = [] # Train loss for discriminator\n",
        "gen_losses = [] # Train loss for generator\n",
        "batch_idx = 0\n",
        "\n",
        "for iter in range(NUM_ITERATIONS):\n",
        "  print(\"ITER #\", step)\n",
        "  for step in range(DISC_STEPS):\n",
        "    disc_net.zero_grad()\n",
        "    print(\"STEP #\", step)\n",
        "    real_batch = image_batches[batch_idx] # Next batch of real images\n",
        "    batch_idx = (batch_idx+1)%len(image_batches)\n",
        "    fake_batch = torch.stack([gen_net().detach().squeeze(0) for i in range(BATCH_SIZE)]) # Here we generate a batch of fake images\n",
        "    real_preds = disc_net(real_batch)\n",
        "    fake_preds = disc_net(fake_batch)\n",
        "    loss = disc_loss(real_preds, fake_preds)\n",
        "    disc_losses.append(float(loss))\n",
        "    loss.backward()\n",
        "    disc_optimizer.step()\n",
        "  done = False\n",
        "  while not done: # Here we train the generator until it creates an image with probability at least 0.3 of being real. In practice I've found this is better, as otherwise the discriminator could train too fast compared to the generator\n",
        "    gen_net.zero_grad()\n",
        "    fake_batch = torch.stack([gen_net().squeeze(0) for i in range(BATCH_SIZE)])\n",
        "    fake_preds = disc_net(fake_batch)\n",
        "    loss = gen_loss(fake_preds)\n",
        "    for i in range(DISC_STEPS):\n",
        "      gen_losses.append(float(loss))\n",
        "    loss.backward()\n",
        "    gen_optimizer.step()\n",
        "    if float(fake_preds[0]) > 0.3:\n",
        "      done = True\n",
        "torch.save(gen_net.state_dict(), \"gdrive/MyDrive/gen_net\") # Saves models\n",
        "torch.save(disc_net.state_dict(), \"gdrive/MyDrive/disc_net\")"
      ],
      "metadata": {
        "id": "mJIoWNGajNYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRDa6wcxVcVA"
      },
      "outputs": [],
      "source": [
        "plt.plot(disc_losses) # Plots loss functions, and a generated image\n",
        "plt.plot(gen_losses)\n",
        "plt.show()\n",
        "plt.imshow(gen_net().detach().squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GAN: Generative Adversarial Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
